---
layout: post
title: التعلم العميق&#58; مقدمة
---


الذكاء الاصطناعي يتطور كل يوم، والتعلم العميق هو أحد العوامل المساهمة في هذا التطور. فمن هذا المنطلق، تهدف هذه المقالة إلى التعريف بأساسيات التعلم العميق. فسنبدأ بالتعريف بأهم المصطلحات والعوامل المؤثرة في بناء نماذج التعلم العميق، وفي المقال القادم سوف نطبق هذه النماذج برمجياً على بيانات مختلفة.

# التعلم العميق

![_config.yml]({{ site.baseurl }}/images/1-ai-ml-dl.jpeg)

التعلم العميق هو فرع من فروع تعلم الآلة يتعامل مع خوارزميات مستوحاة من بنية الشبكات العصبية في الدماغ البشري. بعبارة أخرى، هو يحاكي طريقة أداء دماغنا لمهمة معينة. تشبه خوارزميات التعلم العميق الطريقة التي يتم بها تنظيم الجهاز العصبي، حيث تتصل كل خلية عصبية بالخلايا الأخرى وتمرر المعلومات فيما بينها.


فبنفس الطريقة التي تعمل بها الخلايا العصبية في المخ، كل خلية في خوارزميات التعلم العميق 1) تأخذ مٌدخل عددي، 2) تعمل بعض العمليات على المدخل، ثم 3) ترسل المخرج الذي إما أن يرسل لخلايا أخرى لعمليات إضافية، أو يكون هو المخرج النهائي.

neuron-768x480.png


![_config.yml]({{ site.baseurl }}/images/2-nn-io.png)

وتكون هذه الخلايا موجودة على ثلاث طبقات أو أكثر. الخلايا الموجودة في الطبقة الأولى تأخذ المدخلات، والطبقة الأخيرة تخرج المخرجات، وما بينهما تسمى الطبقات الخفيّة والتي تستقبل المعلومات من الطبقة السابقة وتعالجها ثم تمررها للطبقة التالية.

![_config.yml]({{ site.baseurl }}/images/3-dl-vs-ml.jpg)

ونجد أن نماذج التعلم العميق يتحسن أدائها كلما زادت البيانات المدخلة، على عكس نماذج تعلم الآلة القديمة التي تتوقف عن التحسن بعد نقطة معينة تسمى نقطة التشبع.

![_config.yml]({{ site.baseurl }}/images/4-feature-extraction.png)

أحد الفروق الجلية بين نماذج تعلم الآلة والتعلم العميق تكمن في مرحلة استخراج الخصائص، حيث تتم بشكل يدوي من الإنسان في تعلم الآلة، بينما يقوم التعلم العميق باستخراج الخصائص بدون تحديدها مسبقاً.

# مثال
غالباً ما تستخدم خوارزميات التعلم العميق لتصنيف الصور، لكونها تستخرج خصائص دقيقة من الصور بشكل تلقائي، كما في الصورة التالية.
image.png

بينما في هذا المقال، سنشرح مثالاً أبسط، وهو توقع نتيجةالاختبار بناء على ساعات النوم وساعات الدراسة. الصورة التالية تتوقع نتيجة طالب درس لساعتين، ونام لمدة 9 ساعات، فكانت النتيجة المتوقعة هي 85 من 100.
0_o8Rb-ztx6G4pjzgu.png





# الأوزان
ذكرنا سابقاً بأن كل خلية تعالج المدخلات لها من الطبقة السابقة، فأول ما تقوم به الخلية هو ضرب قيمة المدخل بوزن معين يتم تحديده عشوائياً في البداية. 


وكلما تعلمت الشبكة العصبية أكثر عن تأثير كل مدخل في نتيجة اختبار الطالب، ستقوم بتعديل الوزن، بحيث تعطي وزناً أعلى للمدخلات الأهم، وكلما قلت الأهمية، قل الوزن. فالمدخلات التي لا تؤثر في درجة الاختبار، سيكون وزنها صفراً.

فمثلاً لو كان المدخل a، وقيمة الوزن هي W. فإن المدخل بعد العملية يساوي a*W1

# الانحياز
بالإضافة إلى الأوزان، يتم إضافة قيمة ثابتة إلى المدخل.
بعد ضرب قيمة المدخل في الوزن، يتم إضافة عدد ثابت يسمى الانحياز ويرمز له بالحرف b. فتصبح المعادلة كالتالي:
aW1+b

# دالة التفعيل
حتى تتم ترجمة المدخلات إلى مخرجات، يتم تطبيق دالة تفعيل على المعادلة السابقة.



In the below diagram we have “n” inputs given as X1 to Xn and corresponding weights Wk1 to Wkn. We have a bias given as bk. The weights are first multiplied to its corresponding input and are then added together along with the bias. Let this be called as u.

u=∑w*x+b



في الرسم البياني أدناه لدينا مدخلات من X1 إلى Xn، يتم ضرب كل مدخل بالوزن المقابل له من Wk1 إلى Wkn. وفي الأخير، يتم إضافة العدد الثابت BK لكل ناتج. ثم يتم حساب مجموع هذه النواتج ولنرمز له بالحرف u.
u=∑w*x+b  

بعد ذلك، يتم تطبيق دالة التفعيل على هذا المجموع f(u) وناتج الدالة يكون مدخل للخلايا في الطبقة التالية، أو مخرج نهائي.

node-output.png

# مثال على دالة تفعيل
أحد أكثر دوال التفعيل استخداماً هي سيجمويد. 
sigmoid(x) = 1/(1+e-x)
sinmoid.png

نتيجة الدالة تكون قيمة بين 0 و 1. لذلك عادة ما يتم استخدامها عند تصنيف النتيجة إلى صنفين فقط، إما ناجح أو راسب، إما مريض أو معافى، وهكذا.


أكتفي بهذا في المقالة الأولى، وختاماً، ألخص ما شرحناه بجزء من تعريف ليبينق يانق للشبكات العصبية:

"الشبكات العصبية تتكون من عدد كبير من الخلايا العصبية الاصطناعية، والمرتبطة ببعضها البعض، حيث تمرر البيانات فيما بينها، وترتبط كل خلية بوزن يتم ضبطه استنادًا إلى "خبرة" الشبكة."



# قاموس
الذكاء الاصطناعي: Artificial Intelligence
التعلم العميق: Deep Learning
الأوزان: Weights
الانحياز: Bias
دالة التفعيل: Activation Function

